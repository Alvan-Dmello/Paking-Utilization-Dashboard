{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Os_n6DFlO3rt",
        "outputId": "3c3a9cbc-a85d-4e10-f777-c40102f2ae49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CardTransaction.csv loaded successfully.\n",
            "Initial shape: (4246646, 9)\n",
            "Shape after date cleaning and filtering: (4242447, 9)\n",
            "         EntranceTime            ExitTime  NoEntry  NoExit\n",
            "1 2021-01-01 00:00:00 2021-01-01 08:34:31        1       0\n",
            "2 2021-01-01 00:00:00 2021-01-01 09:38:30        1       0\n",
            "3 2021-01-01 12:31:44 2021-01-01 13:16:59        0       0\n",
            "4 2021-01-01 14:07:08 2021-01-01 15:01:53        0       0\n",
            "5 2021-01-02 00:00:00 2021-01-02 06:26:17        1       0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-f83a704df8c0>:72: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  hourly_intervals = pd.date_range(start=overall_min_dt.floor('H'),\n",
            "<ipython-input-1-f83a704df8c0>:73: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
            "  end=overall_max_dt.ceil('H'),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of aggregated occupancy data: (1100405, 3)\n",
            "     DateTimeInterval  LotNumber  ActiveCarsCount\n",
            "0 2021-01-01 00:00:00         21                2\n",
            "1 2021-01-01 01:00:00         21                2\n",
            "2 2021-01-01 02:00:00         21                2\n",
            "3 2021-01-01 03:00:00         21                2\n",
            "4 2021-01-01 04:00:00         21                2\n",
            "\n",
            "AggregatedOccupancy.csv created successfully.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 1. Load the CardTransaction data\n",
        "# Adjust the path to your CSV file\n",
        "try:\n",
        "    df_transactions = pd.read_csv('CardTransaction.csv')\n",
        "    print(\"CardTransaction.csv loaded successfully.\")\n",
        "    print(f\"Initial shape: {df_transactions.shape}\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: CardTransaction.csv not found. Please check the file path.\")\n",
        "    exit()\n",
        "\n",
        "# 2. Convert Time Columns to Datetime Objects\n",
        "# Ensure proper format if your times are not standard (e.g., 'HH:MM:SS')\n",
        "# The snippet you showed had '38:30:00', which is problematic if it's not a standard time format.\n",
        "# Assuming standard 'HH:MM:SS' or 'YYYY-MM-DD HH:MM:SS' after your Power Query experience.\n",
        "# If they are just 'HH:MM:SS', you might need to combine with a dummy date.\n",
        "# For simplicity, let's assume they are 'YYYY-MM-DD HH:MM:SS' strings from Power Query.\n",
        "# If they are just 'HH:MM:SS' you'll need to parse them more carefully.\n",
        "\n",
        "# Let's assume EntranceTime and ExitTime columns are in a format like 'YYYY-MM-DD HH:MM:SS' or similar,\n",
        "# even if the snippet showed unusual numbers. You cleaned them in Power Query, so they should be usable.\n",
        "# If they are still just times like '01:31:44', you'd need to combine them with the date first.\n",
        "\n",
        "# The safest way is to ensure your CSV after Power Query has the correct DateTime format.\n",
        "# If not, let's load the *original* CSV and apply the Power Query logic here.\n",
        "\n",
        "# --- Re-implementing Power Query Date Cleaning in Pandas ---\n",
        "# Make sure your original EntranceTime and ExitTime columns are loaded correctly.\n",
        "# If they are not strings in the CSV, pandas will try to infer.\n",
        "# If they are strings, specify format, or let pandas infer:\n",
        "df_transactions['EntranceTime'] = pd.to_datetime(df_transactions['EntranceTime'], errors='coerce')\n",
        "df_transactions['ExitTime'] = pd.to_datetime(df_transactions['ExitTime'], errors='coerce')\n",
        "\n",
        "# Impute missing times based on NoEntry/NoExit flags\n",
        "# Rule 1: No EntranceTime (NoEntry = 1) -> Midnight of ExitTime's day\n",
        "# Use .loc to avoid SettingWithCopyWarning\n",
        "mask_no_entry = df_transactions['NoEntry'] == 1\n",
        "df_transactions.loc[mask_no_entry, 'EntranceTime'] = df_transactions.loc[mask_no_entry, 'ExitTime'].dt.normalize()\n",
        "\n",
        "# Rule 2: No ExitTime (NoExit = 1) -> Midnight after EntranceTime's day\n",
        "mask_no_exit = df_transactions['NoExit'] == 1\n",
        "df_transactions.loc[mask_no_exit, 'ExitTime'] = df_transactions.loc[mask_no_exit, 'EntranceTime'].dt.normalize() + pd.Timedelta(days=1)\n",
        "\n",
        "# Handle cases where BOTH are NaN after imputation (if any, though rules cover most)\n",
        "# This might occur if a row had NaN for both EntranceTime AND ExitTime initially,\n",
        "# and NoEntry/NoExit flags were not 1 (which shouldn't happen based on rules).\n",
        "df_transactions.dropna(subset=['EntranceTime', 'ExitTime'], inplace=True)\n",
        "\n",
        "\n",
        "# Filter data to the specified range (January 1, 2021 - April 30, 2025)\n",
        "start_date = pd.to_datetime('2021-01-01')\n",
        "end_date = pd.to_datetime('2025-04-30')\n",
        "df_transactions = df_transactions[(df_transactions['EntranceTime'] >= start_date) &\n",
        "                                  (df_transactions['EntranceTime'] <= end_date)] # Filter by EntranceTime\n",
        "\n",
        "\n",
        "print(f\"Shape after date cleaning and filtering: {df_transactions.shape}\")\n",
        "print(df_transactions[['EntranceTime', 'ExitTime', 'NoEntry', 'NoExit']].head())\n",
        "\n",
        "# --- Next, we'd proceed with the aggregation logic ---\n",
        "# This is the tricky part.\n",
        "# We'll create a new DataFrame to store hourly occupancy.\n",
        "\n",
        "# Find the overall min and max datetimes to define our intervals\n",
        "overall_min_dt = df_transactions['EntranceTime'].min()\n",
        "overall_max_dt = df_transactions['ExitTime'].max() # Use max exit time for full range\n",
        "\n",
        "# Define intervals (e.g., hourly intervals)\n",
        "# We need intervals that span from the start of the first entry hour to the end of the last exit hour\n",
        "# Let's create a list of all hours in your data range\n",
        "hourly_intervals = pd.date_range(start=overall_min_dt.floor('H'),\n",
        "                                 end=overall_max_dt.ceil('H'),\n",
        "                                 freq='H')\n",
        "\n",
        "# Create a DataFrame to store the aggregated occupancy\n",
        "# This will be the result that we save to CSV\n",
        "hourly_occupancy_df = []\n",
        "\n",
        "# Iterate through each LotNumber\n",
        "for lot_num in df_transactions['LotNumber'].unique():\n",
        "    # Filter transactions for the current lot\n",
        "    lot_transactions = df_transactions[df_transactions['LotNumber'] == lot_num]\n",
        "\n",
        "    # Iterate through each hourly interval\n",
        "    for current_hour_start in hourly_intervals:\n",
        "        current_hour_end = current_hour_start + pd.Timedelta(hours=1)\n",
        "\n",
        "        # Count active cars in this lot during this hour\n",
        "        # A car is active if its entrance time is <= current_hour_end\n",
        "        # AND its exit time is >= current_hour_start\n",
        "        active_cars = lot_transactions[\n",
        "            (lot_transactions['EntranceTime'] <= current_hour_end) &\n",
        "            (lot_transactions['ExitTime'] >= current_hour_start)\n",
        "        ]\n",
        "\n",
        "        # Count distinct card numbers\n",
        "        active_count = active_cars['CardNumber'].nunique()\n",
        "\n",
        "        # Append to our results list\n",
        "        hourly_occupancy_df.append({\n",
        "            'DateTimeInterval': current_hour_start,\n",
        "            'LotNumber': lot_num,\n",
        "            'ActiveCarsCount': active_count\n",
        "        })\n",
        "\n",
        "# Convert the list of dictionaries to a DataFrame\n",
        "hourly_occupancy_final_df = pd.DataFrame(hourly_occupancy_df)\n",
        "\n",
        "print(f\"Shape of aggregated occupancy data: {hourly_occupancy_final_df.shape}\")\n",
        "print(hourly_occupancy_final_df.head())\n",
        "\n",
        "# Save the aggregated data to a new CSV file\n",
        "# This is the file you'd load into Power BI\n",
        "hourly_occupancy_final_df.to_csv('AggregatedOccupancy.csv', index=False)\n",
        "print(\"\\nAggregatedOccupancy.csv created successfully.\")"
      ]
    }
  ]
}